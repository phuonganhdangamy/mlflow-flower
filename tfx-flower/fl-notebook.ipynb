{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "616b0e0a",
   "metadata": {},
   "source": [
    "# TFX  pipeline in Flower framework\n",
    "\n",
    "The notebook is used for local testing, replicating Flower's tutorial to implement client and server at the same place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2827a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n",
      "Flower 1.18.0 / PyTorch 2.2.2+cpu\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "import flwr\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
    "from flwr.server.strategy import FedAvg, FedAdagrad\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr.common import ndarrays_to_parameters, NDArrays, Scalar, Context\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86165acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import absl\n",
    "import tensorflow_model_analysis as tfma\n",
    "from tfx.components import CsvExampleGen\n",
    "from tfx.components import Evaluator\n",
    "from tfx.components import ExampleValidator\n",
    "from tfx.components import Pusher\n",
    "from tfx.components import SchemaGen\n",
    "from tfx.components import StatisticsGen\n",
    "from tfx.components import Trainer\n",
    "from tfx.components import Transform\n",
    "from tfx.dsl.components.common import resolver\n",
    "from tfx.dsl.experimental import latest_blessed_model_resolver\n",
    "from tfx.orchestration import metadata\n",
    "from tfx.orchestration import pipeline\n",
    "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n",
    "from tfx.proto import pusher_pb2\n",
    "from tfx.proto import trainer_pb2\n",
    "from tfx.types import Channel\n",
    "from tfx.types.standard_artifacts import Model\n",
    "from tfx.types.standard_artifacts import ModelBlessing\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8489d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from taxi_utils_native_keras import _build_keras_model\n",
    "\n",
    "def save_model_template(save_path: str):\n",
    "    model = _build_keras_model()\n",
    "    model.save(save_path)\n",
    "\n",
    "# Run once to prepare evaluation model\n",
    "save_model_template(\"taxi_utils_native_keras_model_template\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f2b6a1",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377dc819",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PARTITIONS = 5\n",
    "NUM_CLIENTS = 5\n",
    "BATCH_SIZE = 250\n",
    "CSV_DIR = \"../tfx-flower/data/simple\"\n",
    "\n",
    "FEATURE_COLUMNS = [\"pickup_community_area\", \"fare\", \"trip_start_month\", \"trip_start_hour\", \"trip_start_day\", \"trip_start_timestamp\",\n",
    "                   \"pickup_latitude\", \"pickup_longitude\", \"dropoff_latitude\", \"dropoff_longitude\", \"trip_miles\", \"pickup_census_tract\",\n",
    "                   \"dropoff_census_tract\", \"payment_type\", \"company\", \"trip_seconds\", \"dropoff_community_area\"]\n",
    "\n",
    "TARGET_COLUMN = \"tips\" \n",
    "\n",
    "class TaxiDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.features = torch.tensor(df[FEATURE_COLUMNS].values, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(df[TARGET_COLUMN].values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "def load_datasets(partition_id: int, num_partitions: int):\n",
    "    file_path = os.path.join(CSV_DIR, f\"client_{partition_id+1}.csv\")\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    dataset = TaxiDataset(df)\n",
    "\n",
    "    # 80/20 train/val split\n",
    "    val_size = int(0.2 * len(dataset))\n",
    "    train_size = len(dataset) - val_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "    trainloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    valloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    test_df = pd.read_csv(\"../tfx-flower/data/simple/global_test.csv\")\n",
    "    test_dataset = TaxiDataset(test_df)\n",
    "    testloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    return trainloader, valloader, testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac683887",
   "metadata": {},
   "source": [
    "### TFX Flower Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc466e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'absl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mabsl\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_analysis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtfma\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtfx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcomponents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CsvExampleGen\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'absl'"
     ]
    }
   ],
   "source": [
    "def _create_pipeline(client_id: int, module_file: str, output_dir: str):\n",
    "    data_root = f\"../data/simple/client_{client_id}.csv\"\n",
    "    pipeline_root = f\"{output_dir}/pipeline_client_{client_id}\"\n",
    "    metadata_path = f\"{output_dir}/metadata_client_{client_id}.db\"\n",
    "    serving_model_dir = os.path.join(output_dir, f\"serving_model_client_{client_id}\")\n",
    "\n",
    "    # Brings data into the pipeline or otherwise joins/converts training data.\n",
    "    example_gen = CsvExampleGen(input_base=os.path.dirname(data_root))\n",
    "    \n",
    "    # Computes statistics over data for visualization and example validation.\n",
    "    statistics_gen = StatisticsGen(examples=example_gen.outputs['examples'])\n",
    "\n",
    "    # Generates schema based on statistics files.\n",
    "    schema_gen = SchemaGen(\n",
    "        statistics=statistics_gen.outputs['statistics'],\n",
    "        infer_feature_shape=True)\n",
    "    \n",
    "    # Performs anomaly detection based on statistics and data schema.\n",
    "    example_validator = ExampleValidator(\n",
    "        statistics=statistics_gen.outputs['statistics'],\n",
    "        schema=schema_gen.outputs['schema'])\n",
    "        \n",
    "    # Performs transformations and feature engineering in training and serving.\n",
    "    transform = Transform(\n",
    "        examples=example_gen.outputs['examples'],\n",
    "        schema=schema_gen.outputs['schema'],\n",
    "        module_file=module_file)\n",
    "\n",
    "    # Uses user-provided Python function that implements a model.\n",
    "    trainer = Trainer(\n",
    "        module_file=module_file,\n",
    "        examples=transform.outputs['transformed_examples'],\n",
    "        transform_graph=transform.outputs['transform_graph'],\n",
    "        schema=schema_gen.outputs['schema'],\n",
    "        train_args=trainer_pb2.TrainArgs(num_steps=1000),\n",
    "        eval_args=trainer_pb2.EvalArgs(num_steps=150))\n",
    "\n",
    "    # # Get the latest blessed model for model validation.\n",
    "    # model_resolver = resolver.Resolver(\n",
    "    #     strategy_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n",
    "    #     model=Channel(type=Model),\n",
    "    #     model_blessing=Channel(\n",
    "    #         type=ModelBlessing)).with_id('latest_blessed_model_resolver')\n",
    "\n",
    "    # # Uses TFMA to compute a evaluation statistics over features of a model and\n",
    "    # # perform quality validation of a candidate model (compared to a baseline).\n",
    "    # eval_config = tfma.EvalConfig(\n",
    "    #     model_specs=[\n",
    "    #         tfma.ModelSpec(\n",
    "    #             signature_name='serving_default', label_key='tips_xf',\n",
    "    #             preprocessing_function_names=['transform_features'])\n",
    "    #     ],\n",
    "    #     slicing_specs=[tfma.SlicingSpec()],\n",
    "    #     metrics_specs=[\n",
    "    #         tfma.MetricsSpec(metrics=[\n",
    "    #             tfma.MetricConfig(\n",
    "    #                 class_name='BinaryAccuracy',\n",
    "    #                 threshold=tfma.MetricThreshold(\n",
    "    #                     value_threshold=tfma.GenericValueThreshold(\n",
    "    #                         lower_bound={'value': 0.6}),\n",
    "    #                     # Change threshold will be ignored if there is no\n",
    "    #                     # baseline model resolved from MLMD (first run).\n",
    "    #                     change_threshold=tfma.GenericChangeThreshold(\n",
    "    #                         direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
    "    #                         absolute={'value': -1e-10})))\n",
    "    #         ])\n",
    "    #     ])\n",
    "    # evaluator = Evaluator(\n",
    "    #     examples=example_gen.outputs['examples'],\n",
    "    #     model=trainer.outputs['model'],\n",
    "    #     baseline_model=model_resolver.outputs['model'],\n",
    "    #     eval_config=eval_config)\n",
    "\n",
    "    # # Checks whether the model passed the validation steps and pushes the model\n",
    "    # # to a file destination if check passed.\n",
    "    # pusher = Pusher(\n",
    "    #     model=trainer.outputs['model'],\n",
    "    #     model_blessing=evaluator.outputs['blessing'],\n",
    "    #     push_destination=pusher_pb2.PushDestination(\n",
    "    #         filesystem=pusher_pb2.PushDestination.Filesystem(\n",
    "    #             base_directory=serving_model_dir)))\n",
    "\n",
    "    return pipeline.Pipeline(\n",
    "        pipeline_name=f\"client_{client_id}_pipeline\",\n",
    "        pipeline_root=pipeline_root,\n",
    "        components=[example_gen, statistics_gen, schema_gen, example_validator, transform, trainer],\n",
    "        enable_cache=True,\n",
    "        metadata_connection_config=metadata.sqlite_metadata_connection_config(metadata_path)\n",
    "    )\n",
    "\n",
    "def run_pipeline(client_id: int, module_file: str, output_dir: str):\n",
    "    BeamDagRunner().run(_create_pipeline(client_id=client_id, module_file=module_file, output_dir=output_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b9e8ce",
   "metadata": {},
   "source": [
    "### Flower Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e3f55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters_from_keras_model(model):\n",
    "    return [w.numpy() for w in model.get_weights()]\n",
    "\n",
    "def set_parameters_to_keras_model(model, weights):\n",
    "    model.set_weights(weights)\n",
    "\n",
    "def find_latest_model_path(client_id: int, base_dir=\"tfx_output\"):\n",
    "    model_dir = os.path.join(\"tfx-flower\", base_dir, f\"pipeline_client_{client_id}\", \"Trainer\")\n",
    "    candidates = sorted(glob.glob(os.path.join(model_dir, \"model\", \"*\")), reverse=True)\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f\"No model found in {model_dir}\")\n",
    "    return candidates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00335a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFXFlowerClient(NumPyClient):\n",
    "    def __init__(self, partition_id):\n",
    "        self.partition_id = partition_id\n",
    "        self.model = None\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.partition_id}] get_parameters\")\n",
    "        return [w.numpy() for w in self.model.get_weights()]\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        run_pipeline(self.partition_id, \"taxi_utils_native_keras.py\", \"tfx_output\")\n",
    "        model_path = find_latest_model_path(self.partition_id)\n",
    "        self.model = tf.keras.models.load_model(model_path)\n",
    "        self.model.set_weights(parameters)\n",
    "        return self.get_parameters({}), 1, {}\n",
    "\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] evaluate, config: {config}\")\n",
    "\n",
    "        if self.model is None:\n",
    "            model_path = find_latest_model_path(self.partition_id)\n",
    "            self.model = tf.keras.models.load_model(model_path)\n",
    "            \n",
    "        set_parameters_to_keras_model(self.model, parameters)\n",
    "\n",
    "        # Evaluate on test set (or reuse validation set)\n",
    "        test_path = \"../tfx-flower/data/simple/global_test.csv\"\n",
    "        test_df = pd.read_csv(test_path)\n",
    "        x_test = test_df[FEATURE_COLUMNS].values\n",
    "        y_test = test_df[TARGET_COLUMN].values\n",
    "\n",
    "        loss, accuracy = self.model.evaluate(x_test, y_test, verbose=0)\n",
    "        return float(loss), len(x_test), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "\n",
    "def client_fn(context: Context) -> Client:\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    return TFXFlowerClient(partition_id).to_client()\n",
    "\n",
    "# Create the ClientApp (for simulation)\n",
    "client = ClientApp(client_fn=client_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6095931",
   "metadata": {},
   "source": [
    "### Flower Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c790e279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.simulation import start_simulation\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr.server import ServerConfig\n",
    "\n",
    "ROUNDS = 3\n",
    "\n",
    "def evaluate_global_model(weights):\n",
    "    \"\"\"Evaluate global model using global_test.csv\"\"\"\n",
    "    print(\"[Server] Evaluating global model...\")\n",
    "\n",
    "    # Load global test set\n",
    "    test_df = pd.read_csv(\"../data/simple/global_test.csv\")\n",
    "    x_test = test_df[FEATURE_COLUMNS].values\n",
    "    y_test = test_df[TARGET_COLUMN].values\n",
    "\n",
    "    # Load a fresh model (must match client's architecture)\n",
    "    model = tf.keras.models.load_model(\"taxi_utils_native_keras_model_template\")\n",
    "    model.set_weights(weights)\n",
    "\n",
    "    loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f\"[Server] Global evaluation - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    return loss, {\"accuracy\": accuracy}\n",
    "\n",
    "def get_evaluate_fn():\n",
    "    def evaluate(weights):\n",
    "        return evaluate_global_model(weights)\n",
    "    return evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c64aa3",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50308e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = FedAvg(\n",
    "    fraction_fit=1.0,\n",
    "    min_fit_clients=NUM_CLIENTS,\n",
    "    min_available_clients=NUM_CLIENTS,\n",
    "    on_evaluate_config_fn=lambda rnd: {},\n",
    "    evaluate_fn=get_evaluate_fn()\n",
    "    )\n",
    "\n",
    "start_simulation(\n",
    "    client_app=client,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=ServerConfig(num_rounds=ROUNDS),\n",
    "    client_resources={\"num_cpus\": 1},\n",
    "    strategy=strategy\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
